{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0a3432",
   "metadata": {},
   "source": [
    "# Getting and cleaning data\n",
    "\n",
    "For the project, we retrive the dataset using the api for the open data of the City of Toronto. We clean duplicate identical rows that represent the same event and offence. Then, we examine the yearly counts and filter out old years with insufficient data. Finally, we save the dataset as a csv to be used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9a6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1c084",
   "metadata": {},
   "source": [
    "## Get data using API\n",
    "\n",
    "The City of Toronto Open Data API has an upper limit for the number of records that we can get with each request. Therefore, we adapted an algorithm to retrieve the whole dataset using the limit and offset parameters (found in [this source](https://support.smartbear.com/qacomplete/docs/developer/api/rest/api/reference/paging.html)).\n",
    "\n",
    "Based on the documentation for the API and dataset, we set the url for our requests.\n",
    "\n",
    "We then get the dataset metadata to find the total number of records. We do this by setting the limit parameter to 0 so we only retrieve the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2dd700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'help': 'https://ckan0.cf.opendata.inter.prod-toronto.ca/api/3/action/help_show?name=datastore_search',\n",
      " 'result': {'_links': {'next': '/api/3/action/datastore_search?id=af452875-cfdd-4596-a08a-7b93b65ea4f0&limit=0&offset=0',\n",
      "                       'start': '/api/3/action/datastore_search?id=af452875-cfdd-4596-a08a-7b93b65ea4f0&limit=0'},\n",
      "            'fields': [{'id': '_id', 'type': 'int'},\n",
      "                       {'id': 'EVENT_UNIQUE_ID',\n",
      "                        'info': {'notes': 'Offence Number'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'REPORT_DATE',\n",
      "                        'info': {'notes': 'Date Offence was Reported'},\n",
      "                        'type': 'date'},\n",
      "                       {'id': 'OCC_DATE',\n",
      "                        'info': {'notes': 'Date of Offence'},\n",
      "                        'type': 'date'},\n",
      "                       {'id': 'REPORT_YEAR',\n",
      "                        'info': {'notes': 'Year Offence was Reported'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'REPORT_MONTH',\n",
      "                        'info': {'notes': 'Month Offence was Reported'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'REPORT_DAY',\n",
      "                        'info': {'notes': 'Day of the Month Offence was '\n",
      "                                          'Reported'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'REPORT_DOY',\n",
      "                        'info': {'notes': 'Day of the Year Offence was '\n",
      "                                          'Reported'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'REPORT_DOW',\n",
      "                        'info': {'notes': 'Day of the Week Offence was '\n",
      "                                          'Reported'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'REPORT_HOUR',\n",
      "                        'info': {'notes': 'Hour Offence was Reported'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'OCC_YEAR',\n",
      "                        'info': {'notes': 'Year Offence Occurred'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'OCC_MONTH',\n",
      "                        'info': {'notes': 'Month Offence Occurred'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'OCC_DAY',\n",
      "                        'info': {'notes': 'Day of the Month Offence Occurred'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'OCC_DOY',\n",
      "                        'info': {'notes': 'Day of the Year Offence Occurred'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'OCC_DOW',\n",
      "                        'info': {'notes': 'Day of the Week Offence Occurred'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'OCC_HOUR',\n",
      "                        'info': {'notes': 'Hour Offence Occurred'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'DIVISION',\n",
      "                        'info': {'notes': 'Police Division where Offence '\n",
      "                                          'Occurred'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'LOCATION_TYPE',\n",
      "                        'info': {'notes': 'Location Type of Offence'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'PREMISES_TYPE',\n",
      "                        'info': {'notes': 'Premises Type of Offence'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'UCR_CODE',\n",
      "                        'info': {'notes': 'UCR Code for Offence'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'UCR_EXT',\n",
      "                        'info': {'notes': 'UCR Extension for Offence'},\n",
      "                        'type': 'float8'},\n",
      "                       {'id': 'OFFENCE',\n",
      "                        'info': {'notes': 'Title of Offence'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'MCI_CATEGORY',\n",
      "                        'info': {'notes': 'MCI Category of Occurrence'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'HOOD_158',\n",
      "                        'info': {'notes': 'Identifier of Neighbourhood using '\n",
      "                                          \"City of Toronto's new 158 \"\n",
      "                                          'neighbourhood structure'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'NEIGHBOURHOOD_158',\n",
      "                        'info': {'notes': 'Name of Neighbourhood using City of '\n",
      "                                          \"Toronto's new 158 neighbourhood \"\n",
      "                                          'structure'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'HOOD_140',\n",
      "                        'info': {'notes': 'Identifier of Neighbourhood using '\n",
      "                                          \"City of Toronto's old 140 \"\n",
      "                                          'neighbourhood structure'},\n",
      "                        'type': 'text'},\n",
      "                       {'id': 'NEIGHBOURHOOD_140',\n",
      "                        'info': {'notes': 'Name of Neighbourhood using City of '\n",
      "                                          \"Toronto's old 140 neighbourhood \"\n",
      "                                          'structure'},\n",
      "                        'type': 'text'}],\n",
      "            'include_total': True,\n",
      "            'limit': 0,\n",
      "            'records': [],\n",
      "            'records_format': 'objects',\n",
      "            'resource_id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0',\n",
      "            'total': 323296,\n",
      "            'total_estimation_threshold': None,\n",
      "            'total_was_estimated': False},\n",
      " 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Base url for all toronto open data\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\"\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "p = {\"id\": \"major-crime-indicators\"}\n",
    "# get package resources\n",
    "package = requests.get(url, params = p).json()\n",
    "# Look at resources and find the one that is datastore_active\n",
    "for resource in package[\"result\"][\"resources\"]:\n",
    "    # once we find the datastore_active resource, get the id\n",
    "    if resource[\"datastore_active\"]:\n",
    "        resource_id = resource[\"id\"]\n",
    "# using that id and limit 0, get just the metadata first to find total items\n",
    "# based on this algorithm:\n",
    "# https://support.smartbear.com/qacomplete/docs/developer/api/rest/api/reference/paging.html\n",
    "limit = 0\n",
    "\n",
    "# build url for retrieve data\n",
    "url = base_url + \"/api/3/action/datastore_search\"\n",
    "# include resource id and limit in url parameters\n",
    "p = {\n",
    "    'id': resource_id,\n",
    "    'limit': limit\n",
    "}\n",
    "# get metadata, and pprint it to find total items\n",
    "metadata = requests.get(url, params = p).json()\n",
    "pprint(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5720cd",
   "metadata": {},
   "source": [
    "Looking at the metadata, we find the total number of records within the item named 'result' and then 'total', so we save it to a variable. We also note that the actual data will be contained within the same 'result' item but in the subitem 'records'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e36df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323296"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total items from metadata\n",
    "total_items = metadata['result']['total']\n",
    "total_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c825a6",
   "metadata": {},
   "source": [
    "We are now ready to make the requests to retrieve the data. We set the limit parameter to the maximum that can be retrieved each time, based on the documentation (i.e. 32000). The offset parameter, which sets the starting record to retrieve will start at 0, since we want to start with the first record and increase by the limit amount each time we make a request. Each request will extend a list that contains the data and add the records retrieved in that request. We will repeat the request until the offset parameter is above the total number we found in the metadata. Then, we create a pandas dataframe using the final data list. At the end, we compare the total number that we got initially to the number of rows in the dataframe, to make sure they are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f97d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request #1 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 0}\n",
      "request #2 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 32000}\n",
      "request #3 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 64000}\n",
      "request #4 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 96000}\n",
      "request #5 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 128000}\n",
      "request #6 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 160000}\n",
      "request #7 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 192000}\n",
      "request #8 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 224000}\n",
      "request #9 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 256000}\n",
      "request #10 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 288000}\n",
      "request #11 with parameters: {'id': 'af452875-cfdd-4596-a08a-7b93b65ea4f0', 'limit': 32000, 'offset': 320000}\n",
      "\n",
      "The total items in dataset is 323296 and we got 323296.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>EVENT_UNIQUE_ID</th>\n",
       "      <th>REPORT_DATE</th>\n",
       "      <th>OCC_DATE</th>\n",
       "      <th>REPORT_YEAR</th>\n",
       "      <th>REPORT_MONTH</th>\n",
       "      <th>REPORT_DAY</th>\n",
       "      <th>REPORT_DOY</th>\n",
       "      <th>REPORT_DOW</th>\n",
       "      <th>REPORT_HOUR</th>\n",
       "      <th>...</th>\n",
       "      <th>LOCATION_TYPE</th>\n",
       "      <th>PREMISES_TYPE</th>\n",
       "      <th>UCR_CODE</th>\n",
       "      <th>UCR_EXT</th>\n",
       "      <th>OFFENCE</th>\n",
       "      <th>MCI_CATEGORY</th>\n",
       "      <th>HOOD_158</th>\n",
       "      <th>NEIGHBOURHOOD_158</th>\n",
       "      <th>HOOD_140</th>\n",
       "      <th>NEIGHBOURHOOD_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GO-20141262074</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Apartment (Rooming House, Condo)</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1480</td>\n",
       "      <td>110</td>\n",
       "      <td>Administering Noxious Thing</td>\n",
       "      <td>Assault</td>\n",
       "      <td>38</td>\n",
       "      <td>Lansing-Westgate</td>\n",
       "      <td>38</td>\n",
       "      <td>Lansing-Westgate (38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GO-20141260701</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Commercial Dwelling Unit (Hotel, Motel, B &amp; B,...</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>2120</td>\n",
       "      <td>200</td>\n",
       "      <td>B&amp;E</td>\n",
       "      <td>Break and Enter</td>\n",
       "      <td>70</td>\n",
       "      <td>South Riverdale</td>\n",
       "      <td>70</td>\n",
       "      <td>South Riverdale (70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GO-20141260889</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Apartment (Rooming House, Condo)</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1430</td>\n",
       "      <td>100</td>\n",
       "      <td>Assault</td>\n",
       "      <td>Assault</td>\n",
       "      <td>74</td>\n",
       "      <td>North St.James Town</td>\n",
       "      <td>74</td>\n",
       "      <td>North St.James Town (74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GO-20141260973</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Streets, Roads, Highways (Bicycle Path, Privat...</td>\n",
       "      <td>Outside</td>\n",
       "      <td>2130</td>\n",
       "      <td>210</td>\n",
       "      <td>Theft Over</td>\n",
       "      <td>Theft Over</td>\n",
       "      <td>NSA</td>\n",
       "      <td>NSA</td>\n",
       "      <td>NSA</td>\n",
       "      <td>NSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>GO-20141261050</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Streets, Roads, Highways (Bicycle Path, Privat...</td>\n",
       "      <td>Outside</td>\n",
       "      <td>1430</td>\n",
       "      <td>100</td>\n",
       "      <td>Assault</td>\n",
       "      <td>Assault</td>\n",
       "      <td>69</td>\n",
       "      <td>Blake-Jones</td>\n",
       "      <td>66</td>\n",
       "      <td>Danforth (66)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id EVENT_UNIQUE_ID REPORT_DATE    OCC_DATE  REPORT_YEAR REPORT_MONTH  \\\n",
       "0    1  GO-20141262074  2014-01-01  1998-06-01         2014      January   \n",
       "1    2  GO-20141260701  2014-01-01  2014-01-01         2014      January   \n",
       "2    3  GO-20141260889  2014-01-01  2014-01-01         2014      January   \n",
       "3    4  GO-20141260973  2014-01-01  2014-01-01         2014      January   \n",
       "4    5  GO-20141261050  2014-01-01  2014-01-01         2014      January   \n",
       "\n",
       "   REPORT_DAY  REPORT_DOY  REPORT_DOW  REPORT_HOUR  ...  \\\n",
       "0           1           1  Wednesday          12.0  ...   \n",
       "1           1           1  Wednesday           3.0  ...   \n",
       "2           1           1  Wednesday           4.0  ...   \n",
       "3           1           1  Wednesday           4.0  ...   \n",
       "4           1           1  Wednesday           4.0  ...   \n",
       "\n",
       "                                       LOCATION_TYPE PREMISES_TYPE  UCR_CODE  \\\n",
       "0                   Apartment (Rooming House, Condo)     Apartment      1480   \n",
       "1  Commercial Dwelling Unit (Hotel, Motel, B & B,...    Commercial      2120   \n",
       "2                   Apartment (Rooming House, Condo)     Apartment      1430   \n",
       "3  Streets, Roads, Highways (Bicycle Path, Privat...       Outside      2130   \n",
       "4  Streets, Roads, Highways (Bicycle Path, Privat...       Outside      1430   \n",
       "\n",
       "   UCR_EXT                      OFFENCE     MCI_CATEGORY HOOD_158  \\\n",
       "0      110  Administering Noxious Thing          Assault       38   \n",
       "1      200                          B&E  Break and Enter       70   \n",
       "2      100                      Assault          Assault       74   \n",
       "3      210                   Theft Over       Theft Over      NSA   \n",
       "4      100                      Assault          Assault       69   \n",
       "\n",
       "     NEIGHBOURHOOD_158 HOOD_140         NEIGHBOURHOOD_140  \n",
       "0     Lansing-Westgate       38     Lansing-Westgate (38)  \n",
       "1      South Riverdale       70      South Riverdale (70)  \n",
       "2  North St.James Town       74  North St.James Town (74)  \n",
       "3                  NSA      NSA                       NSA  \n",
       "4          Blake-Jones       66             Danforth (66)  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update parameters to include both limit and offset\n",
    "# From documentation, we know the max limit is 32000\n",
    "# so we set, limit to that\n",
    "p['limit'] = 32000\n",
    "\n",
    "# offset will start at 0 and increase by 32000 each loop time\n",
    "p['offset'] = 0\n",
    "\n",
    "# create list to contain data\n",
    "data_list = []\n",
    "\n",
    "n = 1\n",
    "\n",
    "# While offset is under total_items\n",
    "while p['offset'] < total_items:\n",
    "    # log number of request and parameters to be used\n",
    "    print(f\"request #{n} with parameters: {p}\")\n",
    "    # get data that is inside 'result' and 'records'\n",
    "    data = requests.get(url, params = p).json()['result']['records']\n",
    "    # extend data list\n",
    "    data_list.extend(data)\n",
    "    # To finish loop section, increase offset by limit\n",
    "    p['offset'] += p['limit']\n",
    "    n += 1\n",
    "\n",
    "# Create dataframe with data\n",
    "df = pd.DataFrame(data_list)\n",
    "# print total length of dataframe, to confirm we got everything\n",
    "print(f\"\\nThe total items in dataset is {total_items} and we got {len(df)}.\")\n",
    "\n",
    "# Check head of dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ed5cf",
   "metadata": {},
   "source": [
    "## Clean duplicates\n",
    "\n",
    "The dataset page description says that: \n",
    "\n",
    "> This data is provided at the offence and/or victim level, therefore one occurrence number may have several rows of data associated to the various MCIs used to categorize the occurrence.\n",
    "\n",
    "Therefore, we decided to consider rows that are identical (i.e. same event ID and Offence) as a single data point, keeping those with the same event ID but different Offence name as separate.\n",
    "\n",
    "So now we drop duplicate row values that have the same event id and offence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a270ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVENT_UNIQUE_ID  OFFENCE               \n",
       "GO-20141035797   Assault                   1\n",
       "GO-20201253785   B&E                       1\n",
       "GO-2020125466    Assault Bodily Harm       1\n",
       "GO-20201254652   Theft Of Motor Vehicle    1\n",
       "GO-20201254386   Theft Of Motor Vehicle    1\n",
       "                                          ..\n",
       "GO-20171529777   Assault                   1\n",
       "GO-20171529763   Theft Of Motor Vehicle    1\n",
       "GO-20171529587   B&E                       1\n",
       "GO-20171529586   Assault                   1\n",
       "GO-2022999907    Assault                   1\n",
       "Length: 299830, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_duplicates_df = df.drop_duplicates(['EVENT_UNIQUE_ID', 'OFFENCE'])\n",
    "\n",
    "# confirm that there are no duplicates of the same event and offence\n",
    "no_duplicates_df[['EVENT_UNIQUE_ID', 'OFFENCE']].value_counts(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedd3100",
   "metadata": {},
   "source": [
    "## Check annual counts\n",
    "\n",
    "We now check how many records we have per year, to decide if we are using all years or just some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a44da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCC_YEAR\n",
       "2000.0       27\n",
       "2001.0       20\n",
       "2002.0       18\n",
       "2003.0       13\n",
       "2004.0       25\n",
       "2005.0       26\n",
       "2006.0       12\n",
       "2007.0       31\n",
       "2008.0       44\n",
       "2009.0       70\n",
       "2010.0       95\n",
       "2011.0      129\n",
       "2012.0      185\n",
       "2013.0      566\n",
       "2014.0    30202\n",
       "2015.0    30641\n",
       "2016.0    31157\n",
       "2017.0    32790\n",
       "2018.0    34772\n",
       "2019.0    37114\n",
       "2020.0    32456\n",
       "2021.0    32114\n",
       "2022.0    37226\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check counts of occurance year\n",
    "\n",
    "df_by_year = no_duplicates_df.groupby('OCC_YEAR').size()\n",
    "\n",
    "df_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c851ab",
   "metadata": {},
   "source": [
    "From these counts, we see that data that occured before 2014 is likely incomplete, so we decided to filter out the years before 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b88e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCC_YEAR\n",
       "2014.0    30202\n",
       "2015.0    30641\n",
       "2016.0    31157\n",
       "2017.0    32790\n",
       "2018.0    34772\n",
       "2019.0    37114\n",
       "2020.0    32456\n",
       "2021.0    32114\n",
       "2022.0    37226\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 2014 and over\n",
    "over_2014_df = (no_duplicates_df\n",
    "    .loc[no_duplicates_df['OCC_YEAR'] >= 2014]\n",
    ")\n",
    "# check result\n",
    "over_2014_df.groupby('OCC_YEAR').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1814bf",
   "metadata": {},
   "source": [
    "## Write out data\n",
    "\n",
    "Finally, we write the clean dataframe out to a csv file, so we can use it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f8e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data from 2014 and over\n",
    "over_2014_df.to_csv(\n",
    "    Path('resources', 'mci_no_duplicates_2014_and_over.csv'),\n",
    "    index=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
